{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4e8dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import sys\n",
    "import os\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "from torchvision.transforms import v2\n",
    "from tqdm.auto import tqdm\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff7ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dbf898",
   "metadata": {},
   "source": [
    "### Base model_V0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee92bd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "nb_dir\n",
    "print(nb_dir)\n",
    "\n",
    "if nb_dir not in sys.path:\n",
    "    print(\"Nb dir is not in system path\")\n",
    "    sys.path.append(nb_dir)\n",
    "else:\n",
    "    print(\"Nb dir already exists in sys path\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c3924",
   "metadata": {},
   "source": [
    "### Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768d0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import plot_transformed_image\n",
    "\n",
    "root_image_path = Path().cwd().parent / \"data\" / \"Fast_Food_Classification_V2\" / \"Train\"\n",
    "\n",
    "test_images_path = [f for f in root_image_path.rglob(\"*.jpeg\")]\n",
    "\n",
    "data_transform_v0 = v2.Compose([\n",
    "    # resize image\n",
    "    v2.Resize(size=(64, 64)),\n",
    "\n",
    "    # flip images\n",
    "    v2.RandomHorizontalFlip(p=0.5),\n",
    "\n",
    "    # turn image to torch tensor\n",
    "    v2.ToTensor()\n",
    "])\n",
    "\n",
    "plot_transformed_image(image_path=test_images_path,\n",
    "                       transform=data_transform_v0,\n",
    "                       seed=None,\n",
    "                       n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c19862",
   "metadata": {},
   "source": [
    "### DataLoader & ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b263eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We skipped the train/test/validation split since the dataset had already been filtered\n",
    "\n",
    "root_train_folder_path = Path().cwd().parent / \"data\" / \"Fast_Food_Classification_V2\" / \"Train\"\n",
    "root_validation_folder_path = Path().cwd().parent / \"data\" / \"Fast_Food_Classification_V2\" / \"Valid\"\n",
    "root_test_folder_path = Path().cwd().parent / \"data\" / \"Fast_Food_Classification_V2\" / \"Test\"\n",
    "\n",
    "train_dataset = ImageFolder(root=root_train_folder_path,\n",
    "                            transform=data_transform_v0,\n",
    "                            target_transform=None,  \n",
    "                            allow_empty=True)\n",
    "\n",
    "validation_dataset = ImageFolder(root=root_validation_folder_path,\n",
    "                            transform=data_transform_v0,\n",
    "                            target_transform=None,\n",
    "                            allow_empty=True)\n",
    "\n",
    "test_dataset = ImageFolder(root=root_test_folder_path,\n",
    "                            transform=data_transform_v0,\n",
    "                            target_transform=None,\n",
    "                            allow_empty=True)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=32,\n",
    "                              num_workers=1,\n",
    "                              shuffle=True)\n",
    "\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset,\n",
    "                              batch_size=32,\n",
    "                              num_workers=1,\n",
    "                              shuffle=False)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=32,\n",
    "                              num_workers=1,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0836f135",
   "metadata": {},
   "source": [
    "### Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be707a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.model_0 import Cnn_v0\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "model_0 = Cnn_v0(input_shape=3,\n",
    "                 hidden_units=10,\n",
    "                 output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# model_0.conv_block_2(model_0.conv_block_1(torch.rand(32, 3, 64, 64).to(device))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7803d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_utils import train_step, valid_step, test_step, train\n",
    "from classes.helpers import EarlyStopping\n",
    "\n",
    "NUM_EPOCHS = 24\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5,\n",
    "                               delta=0.001,\n",
    "                               verbose=True)\n",
    "\n",
    "start_time = timer()\n",
    "model_0_results = train(model=model_0,\n",
    "                optimizer=optimizer,\n",
    "                loss_fn=loss_fn,\n",
    "                train_dataloader=train_dataloader,\n",
    "                validation_dataloader=validation_dataloader,\n",
    "                early_stopping=early_stopping,\n",
    "                n_epochs=NUM_EPOCHS)\n",
    "\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")\n",
    "print(\"MODEL 0 RESULTS : \", model_0_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a600db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in model_0_results.items():\n",
    "    print(f\"{key} : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f951d3",
   "metadata": {},
   "source": [
    "### Plot Evaluation Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.util import plot_eval_curves\n",
    "\n",
    "plot_eval_curves(model_0_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b5250f",
   "metadata": {},
   "source": [
    "### Model is underfitting\n",
    "- Training accuracy is still low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3705e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use model_1\n",
    "from classes.model_1 import Cnn_v1\n",
    "\n",
    "model_1 = Cnn_v1(input_shape=3,\n",
    "                 hidden_units=10,\n",
    "                 output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(params=model_1.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7679ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_1_results = train(model=model_1,\n",
    "                        optimizer=optimizer_1,\n",
    "                        loss_fn=loss_fn,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        validation_dataloader=validation_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        n_epochs=NUM_EPOCHS)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94bf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_curves(model_1_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035adf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use data augmentation\n",
    "\n",
    "data_transform_v1 = v2.Compose(\n",
    "    [\n",
    "        v2.Resize(size=(64, 64)),\n",
    "        v2.RandomHorizontalFlip(p=0.5),\n",
    "        v2.ToTensor(),\n",
    "        v2.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = ImageFolder(root=root_train_folder_path,\n",
    "                            transform=data_transform_v1,\n",
    "                            target_transform=None,  \n",
    "                            allow_empty=True)\n",
    "\n",
    "validation_dataset = ImageFolder(root=root_validation_folder_path,\n",
    "                            transform=data_transform_v1,\n",
    "                            target_transform=None,\n",
    "                            allow_empty=True)\n",
    "\n",
    "test_dataset = ImageFolder(root=root_test_folder_path,\n",
    "                            transform=data_transform_v1,\n",
    "                            target_transform=None,\n",
    "                            allow_empty=True)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                              batch_size=64,\n",
    "                              num_workers=1,\n",
    "                              shuffle=True)\n",
    "\n",
    "validation_dataloader = DataLoader(dataset=validation_dataset,\n",
    "                              batch_size=64,\n",
    "                              num_workers=1,\n",
    "                              shuffle=False)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                              batch_size=64,\n",
    "                              num_workers=1,\n",
    "                              shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b6b56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes.helpers import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=5,\n",
    "                               delta=0.0001,\n",
    "                               verbose=True)\n",
    "model_1 = Cnn_v1(input_shape=3,\n",
    "                 hidden_units=[32, 64, 128, 256, 512],\n",
    "                 output_shape=len(train_dataset.classes)).to(device)\n",
    "\n",
    "optimizer_1 = torch.optim.Adam(params=model_1.parameters(),\n",
    "                             lr=0.001)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b5b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_1_results = train(model=model_1,\n",
    "                        optimizer=optimizer_1,\n",
    "                        loss_fn=loss_fn,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        validation_dataloader=validation_dataloader,\n",
    "                        n_epochs=NUM_EPOCHS)\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total training time: {end_time-start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d425608b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
